{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v3_large', pretrained=True)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): Conv2dNormActivation(\n",
       "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision.models import mobilenet_v3_large\n",
    "\n",
    "# Initialize the model\n",
    "model = mobilenet_v3_large()\n",
    "\n",
    "# Load the saved state_dict into the model\n",
    "model.load_state_dict(torch.load('mobilenet_v3_large.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "# import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "# try: urllib.URLopener().retrieve(url, filename)\n",
    "# except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.1927e+00, -2.0503e+00, -1.0217e+01, -1.0502e+01, -6.2262e+00,\n",
      "        -4.6185e+00, -7.4292e+00,  2.2277e+00,  5.8748e+00, -4.9711e+00,\n",
      "        -4.5691e+00, -3.7786e+00, -5.9400e+00, -7.6088e+00, -4.4128e+00,\n",
      "        -4.8784e+00, -4.5250e+00, -4.1160e+00, -1.9274e+00, -7.5734e+00,\n",
      "        -3.4837e+00, -6.2416e+00, -5.0570e+00, -4.1671e+00, -3.4238e+00,\n",
      "        -6.6778e+00, -2.6290e+00, -3.4149e+00, -8.0935e+00, -3.5094e+00,\n",
      "        -4.5985e+00, -3.3810e+00, -1.2962e+00, -8.1429e+00, -3.6478e+00,\n",
      "        -3.1890e+00, -3.3857e+00, -5.4922e+00, -5.5387e+00, -6.4920e+00,\n",
      "        -5.1329e+00, -8.7276e+00, -7.8847e+00, -8.5348e+00, -7.9882e+00,\n",
      "        -8.5054e+00, -5.5887e+00, -5.0279e+00, -7.7051e+00, -5.7837e+00,\n",
      "        -6.1633e+00, -7.2985e+00, -3.9971e+00, -5.0512e+00, -3.1074e+00,\n",
      "        -4.5631e+00, -5.4305e+00, -6.6597e+00, -4.4328e+00, -4.1609e+00,\n",
      "        -3.2838e+00, -5.5807e+00, -7.6141e+00, -5.8370e+00, -9.6701e+00,\n",
      "        -7.5837e+00, -6.1189e+00, -5.4042e+00, -6.2283e+00, -9.9330e+00,\n",
      "        -5.8071e+00, -6.6703e+00, -8.6528e+00, -5.9402e+00, -4.7339e+00,\n",
      "        -6.9300e+00, -7.8704e+00, -5.3759e+00, -3.6531e+00, -4.6259e+00,\n",
      "        -2.7794e+00, -2.6344e+00,  1.4927e+00, -3.1229e+00,  1.2936e+00,\n",
      "        -1.4392e+00,  6.8292e-01, -1.1050e+01, -3.5041e+00, -1.0164e+00,\n",
      "        -4.2696e+00, -4.9833e+00, -5.1908e+00, -5.7658e+00, -4.4703e+00,\n",
      "        -7.3688e+00, -4.5224e+00, -2.0568e+00, -2.8166e+00, -3.0463e+00,\n",
      "        -4.1547e+00, -9.8052e+00, -4.7853e+00, -6.5656e+00,  9.3212e+00,\n",
      "        -6.7499e+00, -4.1415e+00, -7.3439e+00,  4.5904e-01, -5.8058e+00,\n",
      "        -4.7793e+00, -7.6279e+00, -3.4806e+00, -3.1602e+00, -2.6177e+00,\n",
      "        -4.4022e+00, -5.5431e+00, -6.0302e+00, -4.8281e+00, -3.2691e-01,\n",
      "        -7.4270e+00, -7.7652e+00, -5.9415e+00, -6.3216e+00, -1.8103e+00,\n",
      "        -3.6531e+00, -5.2905e+00, -1.4377e+00, -3.4742e+00, -3.2487e+00,\n",
      "        -3.0248e+00, -4.7052e+00, -4.6230e+00, -6.5936e+00, -3.7989e+00,\n",
      "        -4.3281e+00, -1.9329e+00, -3.9168e+00, -5.3916e+00, -9.6478e+00,\n",
      "        -8.1831e+00, -9.0334e+00, -6.6114e+00, -6.6836e+00,  2.7634e-01,\n",
      "        -4.5584e+00, -5.7070e+00, -1.1493e+01, -7.8541e+00, -7.1402e+00,\n",
      "        -8.4342e+00,  5.1492e+00,  7.4367e+00,  2.0137e+00,  4.8132e+00,\n",
      "        -1.2199e+00, -5.4530e+00,  4.6671e+00, -1.8732e+00, -1.5395e+00,\n",
      "        -5.2562e+00, -5.6998e+00, -2.9326e+00, -5.5565e+00, -2.1460e+00,\n",
      "        -5.3021e+00, -2.7122e+00, -6.3996e+00, -3.5219e+00,  3.2451e+00,\n",
      "        -4.1270e-01, -3.2034e+00, -2.4840e+00,  6.7470e-01,  6.4935e+00,\n",
      "        -2.0019e+00, -3.7288e+00, -2.2635e+00, -4.0709e+00, -3.4365e+00,\n",
      "        -3.1590e+00, -8.6651e+00,  1.9123e+00, -1.7439e+00, -1.0143e+00,\n",
      "        -1.8931e+00,  2.1211e+00, -2.5751e+00, -3.3263e+00, -4.7734e+00,\n",
      "        -3.2055e+00, -3.9607e+00,  3.9279e+00,  9.4420e-01, -5.2954e+00,\n",
      "        -7.3279e-01, -4.9236e+00, -5.4331e-01, -6.4620e+00,  9.1485e-01,\n",
      "         2.7158e+00, -2.4304e+00, -1.1939e+00,  4.5853e+00,  1.0057e+00,\n",
      "        -5.6775e-01, -1.7348e+00,  2.2484e+00, -8.5697e-01, -3.6750e+00,\n",
      "        -3.8183e+00, -3.3641e+00,  5.6698e-01, -2.4604e+00, -1.2394e+00,\n",
      "        -2.3897e+00, -8.7111e-02, -2.3756e-02, -3.3099e+00, -2.4631e+00,\n",
      "         2.1069e-01, -4.6726e+00,  7.9413e+00,  8.7108e+00,  5.1848e+00,\n",
      "         1.9339e-01,  7.8421e-02,  3.6206e+00,  5.0054e-01,  2.1873e+00,\n",
      "         6.7343e+00,  8.0409e+00,  6.7709e+00, -2.3023e+00, -3.0549e+00,\n",
      "         6.4243e+00,  1.1437e+00, -1.4605e-01, -3.2015e+00, -2.0032e+00,\n",
      "         1.0904e+00, -4.2872e+00, -2.5793e+00, -2.8383e+00,  1.5501e-02,\n",
      "        -2.2602e+00, -2.6645e+00,  2.9825e-01,  1.0171e+01,  5.6742e+00,\n",
      "         7.4834e+00, -1.9514e+00, -3.0434e-01,  2.1246e+00, -1.2815e+00,\n",
      "        -1.0878e+00,  2.7748e+00,  9.8537e+00,  1.6241e+01,  1.2086e+01,\n",
      "         4.5087e+00,  9.4048e+00,  3.9566e+00,  2.8311e+00,  2.2682e+00,\n",
      "        -1.9268e+00, -2.9458e+00, -1.2797e+00, -6.1371e+00,  5.3560e+00,\n",
      "         1.0002e+01,  8.5931e-01, -1.2399e-01,  3.3993e+00,  6.8062e-02,\n",
      "        -3.1231e+00, -7.6029e-01,  7.4319e-01,  9.3597e-02,  9.6776e+00,\n",
      "         2.8875e+00, -9.6972e-02,  6.4626e-01,  4.3213e+00,  1.9379e+00,\n",
      "         2.4402e+00, -5.7235e+00,  3.8012e-02, -1.8350e+00, -2.4587e-01,\n",
      "        -6.6237e+00, -2.8300e+00, -1.2744e+00, -1.6463e+00, -5.1499e+00,\n",
      "        -3.9046e+00, -2.4489e+00, -3.6802e+00, -6.3542e+00, -5.4904e+00,\n",
      "        -5.1142e+00, -2.7418e+00, -3.9407e+00, -6.4556e+00, -4.3402e+00,\n",
      "        -4.5787e+00, -3.5040e+00, -4.3330e+00, -6.5913e+00, -6.0819e+00,\n",
      "        -1.6138e+00, -1.6657e+00, -2.5445e+00, -4.4146e+00, -4.4398e+00,\n",
      "        -3.7672e+00, -5.4727e+00, -4.7824e+00, -4.7765e+00, -7.7914e+00,\n",
      "        -7.1898e+00, -6.7854e+00, -6.9558e+00, -4.8322e+00, -5.9271e+00,\n",
      "        -6.6597e+00, -4.8654e+00, -4.2989e+00, -2.0513e-01, -5.9076e+00,\n",
      "         1.6316e+00,  6.2933e+00,  6.7553e+00, -2.8820e+00, -7.8829e-01,\n",
      "         2.2629e+00, -2.8102e+00, -2.2001e+00, -2.6214e+00, -6.4403e+00,\n",
      "        -5.3261e+00, -6.1504e+00, -6.5580e+00, -9.7640e+00, -9.0800e+00,\n",
      "        -4.8029e+00, -6.7077e+00, -5.6764e+00,  9.6368e-02, -8.2530e+00,\n",
      "        -4.7589e+00, -9.3843e+00, -6.8003e+00, -4.8231e+00, -5.4169e+00,\n",
      "         3.1939e+00, -8.7200e-01, -2.7836e+00, -2.6006e-01, -3.8186e-01,\n",
      "        -5.6171e+00,  2.9582e+00, -3.0148e+00, -3.9787e+00, -4.2233e+00,\n",
      "        -8.0776e+00, -6.3716e+00, -6.4433e+00, -9.4770e-01, -3.4666e+00,\n",
      "        -3.0701e+00, -5.4053e+00, -7.8773e+00, -3.9191e+00, -5.3582e+00,\n",
      "        -4.1335e+00, -6.9611e+00, -3.0522e+00, -2.5817e+00, -5.1412e+00,\n",
      "        -2.5370e+00, -3.3632e+00, -3.5353e+00, -7.9417e-01, -3.1936e+00,\n",
      "        -9.6273e+00, -1.1370e+01, -4.8653e+00, -3.3569e+00, -6.4252e+00,\n",
      "        -6.0282e+00, -1.9479e+00, -5.1988e+00, -4.8065e+00, -5.4707e+00,\n",
      "        -7.8771e+00, -4.4121e+00, -6.1397e+00, -5.6213e+00, -4.7630e+00,\n",
      "        -9.6040e+00, -4.9343e+00, -4.2139e+00, -8.9649e+00, -9.3268e+00,\n",
      "        -4.3844e+00, -5.3334e+00, -1.9088e+00, -2.5060e+00, -2.4752e+00,\n",
      "        -1.1190e+01, -7.2469e-01,  9.4797e-01, -8.1151e+00, -4.0627e+00,\n",
      "        -2.9936e+00, -4.8881e+00, -6.8179e-01, -3.7795e+00, -2.7078e+00,\n",
      "        -5.6420e+00, -5.1121e+00, -3.7336e+00, -5.7627e+00, -8.2341e+00,\n",
      "        -3.5179e+00, -4.0199e+00, -2.1218e+00, -9.8152e-01, -2.9363e+00,\n",
      "        -4.1420e+00, -9.4109e-01, -7.9628e+00, -5.7696e+00, -2.2357e+00,\n",
      "        -3.7042e-01, -3.3211e+00, -4.3318e+00, -6.4491e+00, -4.5029e+00,\n",
      "        -3.2010e+00, -4.8708e+00, -1.4048e+00, -3.7703e+00, -2.2894e+00,\n",
      "        -4.5356e+00, -1.4909e+00, -2.3364e+00, -5.6964e+00, -1.9178e+00,\n",
      "        -5.7758e+00, -3.9185e+00, -3.7729e+00, -4.6391e+00, -6.8569e+00,\n",
      "        -4.2374e+00, -3.6672e+00, -3.8686e+00, -1.8787e+00, -1.5083e+00,\n",
      "        -8.0587e-01, -5.0755e+00, -5.6689e-01,  4.0203e+00, -3.2187e+00,\n",
      "        -1.3635e-01, -5.0574e+00, -5.3984e+00, -6.0254e+00, -5.9727e-01,\n",
      "         3.3954e+00, -3.7126e+00, -3.0451e+00, -1.3578e+00, -4.1311e+00,\n",
      "        -2.0360e+00, -6.3227e+00, -3.5987e+00, -1.2741e+00, -2.6033e+00,\n",
      "        -3.0815e+00, -8.5727e+00, -5.0661e+00, -1.9285e+00, -4.7948e+00,\n",
      "        -4.5569e+00, -6.5908e+00, -1.4348e+00, -4.2295e-01, -5.3492e-01,\n",
      "        -5.9963e+00, -4.6112e+00, -5.3843e+00, -5.3071e+00, -6.3135e+00,\n",
      "        -1.5938e+00, -3.7856e+00, -2.6038e+00, -6.2935e+00, -1.3927e+00,\n",
      "        -6.8034e+00, -2.9255e+00, -3.0895e+00, -2.4559e+00,  1.8467e+00,\n",
      "        -2.4095e+00, -3.9559e+00, -2.8341e+00, -4.6130e+00, -7.4646e+00,\n",
      "        -4.3736e+00, -2.2781e+00, -6.2897e+00, -5.1241e+00, -2.5294e+00,\n",
      "        -3.5775e+00, -4.0649e+00, -6.0655e+00, -2.9835e+00, -1.2116e+00,\n",
      "        -4.7370e+00, -4.5240e+00,  1.5157e+00, -2.2217e+00, -4.9989e+00,\n",
      "        -3.1096e+00, -4.2399e+00, -5.0977e+00, -2.4377e+00, -2.8829e+00,\n",
      "        -4.4823e+00, -2.9928e+00, -2.0810e-01, -2.2306e+00, -4.2233e+00,\n",
      "        -4.3334e+00, -3.8730e+00, -2.1025e+00, -3.5265e+00,  4.3210e+00,\n",
      "        -7.0716e+00, -2.6628e+00, -2.4624e+00, -4.0548e+00, -1.0530e+00,\n",
      "        -5.1465e+00, -5.1183e+00, -9.0646e+00, -7.3436e+00, -6.6507e+00,\n",
      "        -7.2033e+00, -2.3797e+00,  2.4636e+00, -2.6742e+00, -1.6752e+00,\n",
      "        -5.6983e+00, -2.6690e+00, -4.6669e+00, -4.5059e+00, -2.7743e+00,\n",
      "        -6.2393e+00, -6.1362e+00, -5.4328e-01, -3.1266e+00, -2.7420e+00,\n",
      "        -7.1439e+00, -4.0902e+00, -1.1850e+00, -9.7302e-01, -5.0183e+00,\n",
      "        -8.4934e+00, -8.2212e+00, -3.2277e+00, -3.9645e+00, -2.0736e+00,\n",
      "        -2.8243e+00, -7.3949e+00, -4.1352e+00,  7.1569e-01, -1.6489e+00,\n",
      "        -2.3691e+00, -3.4333e+00, -6.0461e+00, -5.7466e+00, -5.2760e+00,\n",
      "        -4.3968e+00, -5.8238e+00, -2.3310e+00, -4.9308e+00, -5.6161e+00,\n",
      "        -4.8703e+00, -4.3442e+00, -6.1329e+00, -4.1352e+00, -4.9160e+00,\n",
      "        -6.6763e+00, -2.9507e+00, -5.2395e+00, -3.0371e+00, -6.2563e+00,\n",
      "        -3.1657e+00, -9.3400e-01, -4.4790e+00, -7.9417e+00, -5.6392e+00,\n",
      "        -2.6092e+00, -7.6061e-02, -1.8240e+00, -1.3254e+00, -6.0292e+00,\n",
      "        -2.7467e+00, -3.3999e+00, -5.9097e+00, -7.6142e+00, -4.1961e+00,\n",
      "        -2.3018e+00, -7.1366e+00, -4.4802e+00, -3.0285e+00, -3.4054e+00,\n",
      "        -5.6422e+00, -2.4540e+00, -1.6488e+00, -2.1010e+00, -4.7491e+00,\n",
      "        -2.8860e+00,  7.2540e-01, -3.1668e+00, -4.0945e+00, -3.4759e+00,\n",
      "        -2.8376e+00,  8.3526e-01, -1.3768e+00, -7.2186e+00, -5.9116e+00,\n",
      "        -3.6255e+00, -5.7125e+00, -5.5193e+00, -3.7638e+00, -6.3436e+00,\n",
      "         1.2888e+00, -9.4213e-01, -5.5641e+00, -6.0225e+00, -2.4873e+00,\n",
      "        -6.5654e+00, -2.0896e+00, -4.7189e+00, -4.4102e+00, -5.7071e+00,\n",
      "        -4.0157e+00, -4.5212e+00, -6.1833e+00,  1.0261e+00, -6.9345e+00,\n",
      "        -2.6396e+00, -5.1110e+00, -3.6606e+00, -1.4067e+00,  3.7172e-01,\n",
      "        -3.6212e+00, -8.7208e+00, -6.8190e+00, -6.5624e+00, -4.8445e+00,\n",
      "        -5.7588e+00, -4.8685e+00, -7.1683e+00, -5.5268e+00, -2.0793e+00,\n",
      "        -3.9465e+00, -5.7848e-01, -1.3246e+00, -4.9045e+00, -7.0408e+00,\n",
      "        -3.8515e+00,  3.5560e+00, -5.5508e+00, -2.2590e+00, -5.3029e+00,\n",
      "        -3.2345e+00, -3.3765e+00, -5.1467e+00, -8.2777e+00, -5.2017e+00,\n",
      "        -4.4556e+00, -5.5227e+00, -5.8261e+00, -7.3146e+00, -3.3454e+00,\n",
      "        -9.2328e+00, -9.1279e+00, -5.1328e+00, -4.1290e+00, -5.6525e+00,\n",
      "        -3.9226e+00, -1.6903e+00, -3.9637e+00, -3.2644e+00, -3.2236e+00,\n",
      "         1.2381e-02, -5.7195e+00, -5.6546e+00, -1.7547e+00, -4.0863e+00,\n",
      "        -3.9421e+00, -1.0155e+00, -3.8554e+00, -3.4948e+00, -8.2897e+00,\n",
      "        -5.8426e+00, -1.4274e+00, -5.3420e+00, -7.3175e+00, -4.2525e+00,\n",
      "        -8.4227e+00,  6.8319e-01, -2.3959e+00, -5.6634e+00, -2.8802e+00,\n",
      "        -6.3902e+00, -1.6350e+00, -3.8011e-01, -2.3407e+00, -5.1253e+00,\n",
      "        -2.3602e+00, -9.9277e+00, -4.4162e+00,  1.1273e+00, -1.3474e+00,\n",
      "        -6.1480e+00, -2.6720e-01, -8.9753e+00, -1.8329e+00, -4.3001e+00,\n",
      "        -3.3062e+00, -3.8889e+00, -5.9041e+00,  9.2027e-01, -5.6293e+00,\n",
      "        -6.3815e+00, -4.8414e+00, -4.0851e+00, -2.7939e+00, -2.7554e+00,\n",
      "        -7.1096e+00, -5.5390e+00, -1.3633e+00, -5.6676e+00,  3.6796e+00,\n",
      "        -2.2458e-01, -5.7577e+00, -3.1485e+00,  2.3840e-01, -3.2855e+00,\n",
      "        -6.1488e+00,  2.3197e+00, -3.2001e+00, -2.5229e+00, -6.1163e+00,\n",
      "        -3.3976e+00, -1.4569e+00, -4.4459e+00, -5.0002e+00, -5.3693e+00,\n",
      "        -1.1326e+00, -7.8843e+00, -3.3945e+00,  1.3958e+00, -2.1819e+00,\n",
      "        -4.0399e+00, -1.7196e+00, -4.3756e+00, -1.6950e+00, -3.2226e+00,\n",
      "        -5.4103e+00, -8.9350e+00, -7.5822e+00, -2.6599e+00, -6.2290e+00,\n",
      "        -2.7838e+00, -6.2456e+00, -6.3919e+00, -5.1792e+00, -6.8490e+00,\n",
      "         6.0756e-01, -6.0634e+00, -6.4849e+00, -4.7433e+00,  1.5844e+00,\n",
      "        -1.6992e+00, -6.6448e+00, -1.5717e+00, -5.4079e+00, -2.4888e+00,\n",
      "        -5.6599e+00, -5.6196e+00, -8.1787e-01, -2.9188e+00, -3.3039e+00,\n",
      "        -6.2260e+00, -6.8674e+00, -6.1083e+00, -5.2193e+00, -4.1252e+00,\n",
      "         4.0621e+00, -7.6577e-01, -6.2499e+00, -6.5984e+00, -3.5560e+00,\n",
      "        -4.4802e+00, -1.8566e+00, -7.6833e+00, -2.6531e+00, -4.6317e+00,\n",
      "        -2.5365e+00, -7.0186e+00, -6.4929e+00, -1.4591e+00, -3.2800e+00,\n",
      "        -8.4486e+00, -3.9093e+00, -4.6956e+00, -2.7391e+00, -1.2732e+00,\n",
      "        -3.9492e-01, -3.8226e+00, -3.3912e+00, -2.3739e+00, -6.3183e+00,\n",
      "        -4.0720e+00,  1.4111e+00, -5.3737e+00, -5.0651e+00, -3.7662e+00,\n",
      "        -1.1637e+00, -2.3811e+00, -1.1484e+00, -2.2531e+00, -1.9013e+00,\n",
      "        -1.1267e+00, -1.7523e+00, -3.1071e+00, -4.2655e+00, -3.5267e+00,\n",
      "        -4.8686e+00, -5.0880e+00, -6.1894e+00, -6.1113e+00, -6.9749e-01,\n",
      "        -4.4001e+00, -3.3808e+00,  5.9478e+00, -3.1719e+00, -2.6610e+00,\n",
      "        -1.3821e+00, -5.5102e+00, -5.8330e+00, -6.1542e+00, -6.8754e+00,\n",
      "        -4.1225e+00, -1.7013e+00, -6.3693e-01, -6.4601e+00, -4.3102e+00,\n",
      "        -6.5639e+00, -9.4976e+00, -3.3397e+00, -2.7681e+00, -3.6108e+00,\n",
      "        -2.0039e+00, -3.5285e+00, -6.2815e+00, -5.3146e+00, -7.9596e+00,\n",
      "        -5.1975e+00,  1.8237e+00, -5.8522e+00, -5.4526e+00, -1.4564e+00,\n",
      "        -2.9993e+00, -3.4426e+00, -3.2541e+00, -1.9588e+00, -6.3082e+00,\n",
      "        -7.6335e-01, -5.3661e+00, -7.9766e+00, -3.5294e+00, -4.4370e+00,\n",
      "         6.9427e-01, -4.7314e+00, -3.5917e+00, -5.5333e+00, -2.4716e+00,\n",
      "        -5.1811e+00, -1.2366e+00, -1.3011e+00, -1.6448e+00, -3.3557e+00,\n",
      "        -7.8691e+00, -1.7463e+00, -5.5706e-01, -2.1357e+00,  5.9529e-01,\n",
      "        -2.6801e+00, -6.2410e+00, -4.3758e+00, -3.8682e+00, -5.5217e+00,\n",
      "        -1.8196e+00, -4.1375e-01,  9.4007e-01, -3.9838e+00, -2.2242e+00,\n",
      "        -4.6372e-01, -4.2469e+00, -1.0195e+01, -2.1925e+00, -5.6756e+00,\n",
      "        -7.0934e+00, -5.8280e+00, -3.3166e+00, -3.6368e+00, -4.7438e+00,\n",
      "        -4.4412e+00, -7.3673e+00, -4.2565e+00, -6.5231e+00, -1.3383e+00,\n",
      "        -4.7446e+00, -7.2052e+00, -7.9417e+00, -7.8550e+00, -5.1522e+00,\n",
      "        -6.1364e-01, -2.6312e+00, -3.1329e+00, -1.8840e+00, -5.4806e+00,\n",
      "        -4.5285e+00, -6.5229e+00, -6.3655e+00, -2.2587e+00, -4.0280e+00,\n",
      "        -5.1894e+00, -2.8652e+00, -4.5552e+00, -2.4102e+00, -2.5342e+00,\n",
      "        -3.8067e+00, -2.1092e+00, -5.7272e+00, -1.4058e+00, -6.5105e+00,\n",
      "        -3.4930e+00, -6.2190e+00,  2.0056e-01, -5.0499e-01, -4.6903e+00,\n",
      "        -2.5539e+00, -3.4551e+00, -5.3918e+00, -6.5628e+00, -6.1309e+00,\n",
      "        -5.7518e+00, -3.1975e+00, -3.0523e+00, -7.0866e-01, -3.5343e+00,\n",
      "         3.6198e-01, -2.9460e+00, -2.9661e+00, -3.2181e+00, -1.5030e+00,\n",
      "         2.7154e+00, -2.0594e+00,  6.9275e-01, -3.4721e+00, -1.5963e+00,\n",
      "        -4.3077e+00, -8.3220e+00, -3.3077e+00, -7.6013e+00, -3.3973e+00,\n",
      "        -3.5168e+00, -3.5791e+00, -1.4506e+00, -2.7607e+00, -1.1815e+00,\n",
      "         1.4408e+00, -4.8050e-01, -6.2834e+00, -6.1102e+00, -5.6420e+00,\n",
      "        -2.8304e+00, -2.7786e+00, -7.6346e+00, -3.8195e+00, -1.2029e+00])\n",
      "tensor([1.3007e-09, 1.1082e-08, 3.1467e-12, 2.3660e-12, 1.7023e-10, 8.4972e-10,\n",
      "        5.1122e-11, 7.9894e-07, 3.0649e-05, 5.9723e-10, 8.9273e-10, 1.9679e-09,\n",
      "        2.2664e-10, 4.2715e-11, 1.0438e-09, 6.5523e-10, 9.3295e-10, 1.4044e-09,\n",
      "        1.2531e-08, 4.4255e-11, 2.6431e-09, 1.6763e-10, 5.4804e-10, 1.3345e-09,\n",
      "        2.8062e-09, 1.0837e-10, 6.2128e-09, 2.8312e-09, 2.6308e-11, 2.5759e-09,\n",
      "        8.6686e-10, 2.9288e-09, 2.3558e-08, 2.5041e-11, 2.2431e-09, 3.5487e-09,\n",
      "        2.9152e-09, 3.5467e-10, 3.3855e-10, 1.3051e-10, 5.0801e-10, 1.3955e-11,\n",
      "        3.2415e-11, 1.6921e-11, 2.9229e-11, 1.7426e-11, 3.2205e-10, 5.6421e-10,\n",
      "        3.8794e-11, 2.6498e-10, 1.8128e-10, 5.8259e-11, 1.5818e-09, 5.5123e-10,\n",
      "        3.8504e-09, 8.9813e-10, 3.7725e-10, 1.1035e-10, 1.0231e-09, 1.3427e-09,\n",
      "        3.2278e-09, 3.2463e-10, 4.2491e-11, 2.5122e-10, 5.4374e-12, 4.3803e-11,\n",
      "        1.8952e-10, 3.8729e-10, 1.6988e-10, 4.1804e-12, 2.5885e-10, 1.0919e-10,\n",
      "        1.5038e-11, 2.2659e-10, 7.5710e-10, 8.4213e-11, 3.2883e-11, 3.9840e-10,\n",
      "        2.2311e-09, 8.4342e-10, 5.3453e-09, 6.1796e-09, 3.8310e-07, 3.7913e-09,\n",
      "        3.1395e-07, 2.0418e-08, 1.7047e-07, 1.3683e-12, 2.5895e-09, 3.1163e-08,\n",
      "        1.2044e-09, 5.8998e-10, 4.7943e-10, 2.6976e-10, 9.8545e-10, 5.4303e-11,\n",
      "        9.3542e-10, 1.1010e-08, 5.1499e-09, 4.0931e-09, 1.3511e-09, 4.7499e-12,\n",
      "        7.1915e-10, 1.2124e-10, 9.6207e-04, 1.0083e-10, 1.3690e-09, 5.5674e-11,\n",
      "        1.3627e-07, 2.5920e-10, 7.2345e-10, 4.1908e-11, 2.6512e-09, 3.6525e-09,\n",
      "        6.2835e-09, 1.0548e-09, 3.3706e-10, 2.0710e-10, 6.8903e-10, 6.2097e-08,\n",
      "        5.1234e-11, 3.6532e-11, 2.2630e-10, 1.5474e-10, 1.4088e-08, 2.2312e-09,\n",
      "        4.3394e-10, 2.0449e-08, 2.6683e-09, 3.3432e-09, 4.1820e-09, 7.7915e-10,\n",
      "        8.4585e-10, 1.1789e-10, 1.9284e-09, 1.1360e-09, 1.2462e-08, 1.7140e-09,\n",
      "        3.9221e-10, 5.5598e-12, 2.4054e-11, 1.0278e-11, 1.1581e-10, 1.0775e-10,\n",
      "        1.1352e-07, 9.0234e-10, 2.8612e-10, 8.7831e-13, 3.3423e-11, 6.8250e-11,\n",
      "        1.8713e-11, 1.4836e-05, 1.4614e-04, 6.4505e-07, 1.0603e-05, 2.5426e-08,\n",
      "        3.6883e-10, 9.1610e-06, 1.3230e-08, 1.8470e-08, 4.4906e-10, 2.8817e-10,\n",
      "        4.5861e-09, 3.3258e-10, 1.0070e-08, 4.2890e-10, 5.7171e-09, 1.4313e-10,\n",
      "        2.5440e-09, 2.2098e-06, 5.6992e-08, 3.4981e-09, 7.1820e-09, 1.6907e-07,\n",
      "        5.6903e-05, 1.1632e-08, 2.0684e-09, 8.9540e-09, 1.4691e-09, 2.7708e-09,\n",
      "        3.6570e-09, 1.4854e-11, 5.8285e-07, 1.5055e-08, 3.1227e-08, 1.2969e-08,\n",
      "        7.1820e-07, 6.5566e-09, 3.0936e-09, 7.2772e-10, 3.4907e-09, 1.6404e-09,\n",
      "        4.3743e-06, 2.2136e-07, 4.3181e-10, 4.1381e-08, 6.2624e-10, 5.0014e-08,\n",
      "        1.3447e-10, 2.1496e-07, 1.3017e-06, 7.5778e-09, 2.6095e-08, 8.4416e-06,\n",
      "        2.3542e-07, 4.8806e-08, 1.5193e-08, 8.1571e-07, 3.6548e-08, 2.1827e-09,\n",
      "        1.8913e-09, 2.9787e-09, 1.5180e-07, 7.3540e-09, 2.4934e-08, 7.8925e-09,\n",
      "        7.8925e-08, 8.4087e-08, 3.1446e-09, 7.3340e-09, 1.0630e-07, 8.0494e-10,\n",
      "        2.4205e-04, 5.2254e-04, 1.5373e-05, 1.0448e-07, 9.3134e-08, 3.2170e-06,\n",
      "        1.4205e-07, 7.6735e-07, 7.2393e-05, 2.6741e-04, 7.5097e-05, 8.6134e-09,\n",
      "        4.0582e-09, 5.3097e-05, 2.7025e-07, 7.4408e-08, 3.5048e-09, 1.1616e-08,\n",
      "        2.5622e-07, 1.1835e-09, 6.5293e-09, 5.0397e-09, 8.7454e-08, 8.9840e-09,\n",
      "        5.9962e-09, 1.1603e-07, 2.2510e-03, 2.5079e-05, 1.5312e-04, 1.2233e-08,\n",
      "        6.3515e-08, 7.2068e-07, 2.3905e-08, 2.9014e-08, 1.3808e-06, 1.6386e-03,\n",
      "        9.7359e-01, 1.5272e-02, 7.8191e-06, 1.0460e-03, 4.5017e-06, 1.4607e-06,\n",
      "        8.3202e-07, 1.2538e-08, 4.5259e-09, 2.3949e-08, 1.8610e-10, 1.8245e-05,\n",
      "        1.8998e-03, 2.0335e-07, 7.6068e-08, 2.5783e-06, 9.2174e-08, 3.7905e-09,\n",
      "        4.0258e-08, 1.8106e-07, 9.4558e-08, 1.3740e-03, 1.5455e-06, 7.8151e-08,\n",
      "        1.6433e-07, 6.4829e-06, 5.9794e-07, 9.8812e-07, 2.8143e-10, 8.9445e-08,\n",
      "        1.3744e-08, 6.7339e-08, 1.1440e-10, 5.0815e-09, 2.4076e-08, 1.6598e-08,\n",
      "        4.9944e-10, 1.7349e-09, 7.4386e-09, 2.1716e-09, 1.4978e-10, 3.5532e-10,\n",
      "        5.1759e-10, 5.5501e-09, 1.6735e-09, 1.3534e-10, 1.1223e-09, 8.8418e-10,\n",
      "        2.5898e-09, 1.1305e-09, 1.1816e-10, 1.9666e-10, 1.7146e-08, 1.6280e-08,\n",
      "        6.7609e-09, 1.0419e-09, 1.0159e-09, 1.9905e-09, 3.6165e-10, 7.2124e-10,\n",
      "        7.2554e-10, 3.5587e-11, 6.4950e-11, 9.7317e-11, 8.2073e-11, 6.8617e-10,\n",
      "        2.2958e-10, 1.1036e-10, 6.6379e-10, 1.1696e-09, 7.0140e-08, 2.3411e-10,\n",
      "        4.4018e-07, 4.6581e-05, 7.3933e-05, 4.8242e-09, 3.9147e-08, 8.2759e-07,\n",
      "        5.1833e-09, 9.5404e-09, 6.2605e-09, 1.3743e-10, 4.1874e-10, 1.8363e-10,\n",
      "        1.2217e-10, 4.9498e-12, 9.8099e-12, 7.0660e-10, 1.0518e-10, 2.9499e-10,\n",
      "        9.4820e-08, 2.2430e-11, 7.3839e-10, 7.2358e-12, 9.5879e-11, 6.9247e-10,\n",
      "        3.8238e-10, 2.0996e-06, 3.6003e-08, 5.3229e-09, 6.6391e-08, 5.8777e-08,\n",
      "        3.1301e-10, 1.6587e-06, 4.2239e-09, 1.6111e-09, 1.2615e-09, 2.6731e-11,\n",
      "        1.4720e-10, 1.3702e-10, 3.3379e-08, 2.6887e-09, 3.9967e-09, 3.8686e-10,\n",
      "        3.2659e-11, 1.7101e-09, 4.0552e-10, 1.3801e-09, 8.1637e-11, 4.0689e-09,\n",
      "        6.5137e-09, 5.0381e-10, 6.8117e-09, 2.9813e-09, 2.5102e-09, 3.8918e-08,\n",
      "        3.5324e-09, 5.6749e-12, 9.9295e-13, 6.6388e-10, 3.0004e-09, 1.3951e-10,\n",
      "        2.0751e-10, 1.2277e-08, 4.7559e-10, 7.0406e-10, 3.6236e-10, 3.2663e-11,\n",
      "        1.0445e-09, 1.8561e-10, 3.1171e-10, 7.3537e-10, 5.8088e-12, 6.1959e-10,\n",
      "        1.2734e-09, 1.1006e-11, 7.6644e-12, 1.0738e-09, 4.1571e-10, 1.2766e-08,\n",
      "        7.0261e-09, 7.2457e-09, 1.1888e-12, 4.1717e-08, 2.2220e-07, 2.5746e-11,\n",
      "        1.4813e-09, 4.3145e-09, 6.4887e-10, 4.3546e-08, 1.9662e-09, 5.7422e-09,\n",
      "        3.0531e-10, 5.1865e-10, 2.0587e-09, 2.7061e-10, 2.2857e-11, 2.5542e-09,\n",
      "        1.5461e-09, 1.0317e-08, 3.2269e-08, 4.5690e-09, 1.3684e-09, 3.3600e-08,\n",
      "        2.9981e-11, 2.6874e-10, 9.2068e-09, 5.9454e-08, 3.1096e-09, 1.1318e-09,\n",
      "        1.3622e-10, 9.5381e-10, 3.5066e-09, 6.6019e-10, 2.1133e-08, 1.9844e-09,\n",
      "        8.7254e-09, 9.2309e-10, 1.9389e-08, 8.3249e-09, 2.8917e-10, 1.2652e-08,\n",
      "        2.6709e-10, 1.7111e-09, 1.9792e-09, 8.3235e-10, 9.0601e-11, 1.2439e-09,\n",
      "        2.1998e-09, 1.7986e-09, 1.3156e-08, 1.9055e-08, 3.8465e-08, 5.3800e-10,\n",
      "        4.8848e-08, 4.7977e-06, 3.4450e-09, 7.5133e-08, 5.4784e-10, 3.8956e-10,\n",
      "        2.0809e-10, 4.7387e-08, 2.5684e-06, 2.1023e-09, 4.0982e-09, 2.2149e-08,\n",
      "        1.3834e-09, 1.1241e-08, 1.5457e-10, 2.3558e-09, 2.4083e-08, 6.3746e-09,\n",
      "        3.9517e-09, 1.6292e-11, 5.4308e-10, 1.2517e-08, 7.1233e-10, 9.0365e-10,\n",
      "        1.1822e-10, 2.0507e-08, 5.6411e-08, 5.0436e-08, 2.1424e-10, 8.5590e-10,\n",
      "        3.9507e-10, 4.2677e-10, 1.5600e-10, 1.7493e-08, 1.9543e-09, 6.3714e-09,\n",
      "        1.5916e-10, 2.1390e-08, 9.5579e-11, 4.6187e-09, 3.9201e-09, 7.3873e-09,\n",
      "        5.4583e-07, 7.7380e-09, 1.6483e-09, 5.0608e-09, 8.5435e-10, 4.9342e-11,\n",
      "        1.0854e-09, 8.8241e-09, 1.5975e-10, 5.1246e-10, 6.8634e-09, 2.4064e-09,\n",
      "        1.4780e-09, 1.9991e-10, 4.3586e-09, 2.5637e-08, 7.5475e-10, 9.3394e-10,\n",
      "        3.9200e-07, 9.3365e-09, 5.8084e-10, 3.8420e-09, 1.2407e-09, 5.2617e-10,\n",
      "        7.5229e-09, 4.8198e-09, 9.7366e-10, 4.3181e-09, 6.9931e-08, 9.2540e-09,\n",
      "        1.2615e-09, 1.1300e-09, 1.7907e-09, 1.0519e-08, 2.5322e-09, 6.4811e-06,\n",
      "        7.3095e-11, 6.0062e-09, 7.3390e-09, 1.4930e-09, 3.0043e-08, 5.0114e-10,\n",
      "        5.1549e-10, 9.9619e-12, 5.5687e-11, 1.1135e-10, 6.4073e-11, 7.9722e-09,\n",
      "        1.0115e-06, 5.9384e-09, 1.6126e-08, 2.8860e-10, 5.9692e-09, 8.0952e-10,\n",
      "        9.5096e-10, 5.3726e-09, 1.6802e-10, 1.8627e-10, 5.0015e-08, 3.7775e-09,\n",
      "        5.5489e-09, 6.7997e-11, 1.4411e-09, 2.6328e-08, 3.2544e-08, 5.6965e-10,\n",
      "        1.7636e-11, 2.3155e-11, 3.4142e-09, 1.6341e-09, 1.0827e-08, 5.1106e-09,\n",
      "        5.2906e-11, 1.3777e-09, 1.7614e-07, 1.6555e-08, 8.0565e-09, 2.7795e-09,\n",
      "        2.0382e-10, 2.7500e-10, 4.4025e-10, 1.0606e-09, 2.5456e-10, 8.3700e-09,\n",
      "        6.2176e-10, 3.1334e-10, 6.6057e-10, 1.1179e-09, 1.8689e-10, 1.3777e-09,\n",
      "        6.3105e-10, 1.0854e-10, 4.5039e-09, 4.5663e-10, 4.1309e-09, 1.6519e-10,\n",
      "        3.6326e-09, 3.3839e-08, 9.7690e-10, 3.0622e-11, 3.0617e-10, 6.3369e-09,\n",
      "        7.9802e-08, 1.3897e-08, 2.2878e-08, 2.0731e-10, 5.5231e-09, 2.8740e-09,\n",
      "        2.3362e-10, 4.2486e-11, 1.2964e-09, 8.6173e-09, 6.8498e-11, 9.7569e-10,\n",
      "        4.1667e-09, 2.8582e-09, 3.0527e-10, 7.4012e-09, 1.6557e-08, 1.0534e-08,\n",
      "        7.4564e-10, 4.8050e-09, 1.7786e-07, 3.6285e-09, 1.4349e-09, 2.6637e-09,\n",
      "        5.0430e-09, 1.9852e-07, 2.1733e-08, 6.3103e-11, 2.3316e-10, 2.2936e-09,\n",
      "        2.8454e-10, 3.4517e-10, 1.9974e-09, 1.5137e-10, 3.1244e-07, 3.3565e-08,\n",
      "        3.3005e-10, 2.0869e-10, 7.1585e-09, 1.2127e-10, 1.0655e-08, 7.6852e-10,\n",
      "        1.0465e-09, 2.8608e-10, 1.5526e-09, 9.3651e-10, 1.7770e-10, 2.4025e-07,\n",
      "        8.3838e-11, 6.1471e-09, 5.1924e-10, 2.2144e-09, 2.1091e-08, 1.2488e-07,\n",
      "        2.3034e-09, 1.4049e-11, 9.4097e-11, 1.2163e-10, 6.7781e-10, 2.7167e-10,\n",
      "        6.6174e-10, 6.6356e-11, 3.4262e-10, 1.0765e-08, 1.6638e-09, 4.8286e-08,\n",
      "        2.2896e-08, 6.3833e-10, 7.5379e-11, 1.8296e-09, 3.0158e-06, 3.3448e-10,\n",
      "        8.9945e-09, 4.2859e-10, 3.3911e-09, 2.9420e-09, 5.0102e-10, 2.1882e-11,\n",
      "        4.7421e-10, 9.9998e-10, 3.4399e-10, 2.5397e-10, 5.7329e-11, 3.0351e-09,\n",
      "        8.4194e-12, 9.3509e-12, 5.0806e-10, 1.3863e-09, 3.0213e-10, 1.7041e-09,\n",
      "        1.5884e-08, 1.6355e-09, 3.2912e-09, 3.4281e-09, 8.7182e-08, 2.8254e-10,\n",
      "        3.0150e-10, 1.4893e-08, 1.4467e-09, 1.6712e-09, 3.1190e-08, 1.8224e-09,\n",
      "        2.6139e-09, 2.1621e-11, 2.4983e-10, 2.0660e-08, 4.1216e-10, 5.7159e-11,\n",
      "        1.2252e-09, 1.8929e-11, 1.7051e-07, 7.8433e-09, 2.9885e-10, 4.8325e-09,\n",
      "        1.4448e-10, 1.6786e-08, 5.8880e-08, 8.2892e-09, 5.1185e-10, 8.1289e-09,\n",
      "        4.2026e-12, 1.0402e-09, 2.6585e-07, 2.2382e-08, 1.8408e-10, 6.5918e-08,\n",
      "        1.0892e-11, 1.3773e-08, 1.1683e-09, 3.1564e-09, 1.7625e-09, 2.3492e-10,\n",
      "        2.1613e-07, 3.0922e-10, 1.4574e-10, 6.7988e-10, 1.4485e-09, 5.2682e-09,\n",
      "        5.4750e-09, 7.0369e-11, 3.3844e-10, 2.2027e-08, 2.9760e-10, 3.4126e-06,\n",
      "        6.8788e-08, 2.7196e-10, 3.6954e-09, 1.0929e-07, 3.2225e-09, 1.8394e-10,\n",
      "        8.7598e-07, 3.5096e-09, 6.9084e-09, 1.9001e-10, 2.8808e-09, 2.0060e-08,\n",
      "        1.0097e-09, 5.8006e-10, 4.0106e-10, 2.7743e-08, 3.2428e-11, 2.8895e-09,\n",
      "        3.4773e-07, 9.7155e-09, 1.5155e-09, 1.5425e-08, 1.0833e-09, 1.5809e-08,\n",
      "        3.4316e-09, 3.8494e-10, 1.1341e-11, 4.3866e-11, 6.0235e-09, 1.6975e-10,\n",
      "        5.3218e-09, 1.6696e-10, 1.4424e-10, 4.8502e-10, 9.1321e-11, 1.5809e-07,\n",
      "        2.0034e-10, 1.3142e-10, 7.5002e-10, 4.1990e-07, 1.5743e-08, 1.1201e-10,\n",
      "        1.7884e-08, 3.8586e-10, 7.1479e-09, 2.9991e-10, 3.1225e-10, 3.8006e-08,\n",
      "        4.6496e-09, 3.1636e-09, 1.7027e-10, 8.9652e-11, 1.9153e-10, 4.6594e-10,\n",
      "        1.3916e-09, 5.0028e-06, 4.0038e-08, 1.6624e-10, 1.1733e-10, 2.4586e-09,\n",
      "        9.7572e-10, 1.3450e-08, 3.9650e-11, 6.0648e-09, 8.3855e-10, 6.8148e-09,\n",
      "        7.7072e-11, 1.3038e-10, 2.0015e-08, 3.2403e-09, 1.8445e-11, 1.7268e-09,\n",
      "        7.8660e-10, 5.5649e-09, 2.4105e-08, 5.8014e-08, 1.8833e-09, 2.8993e-09,\n",
      "        8.0180e-09, 1.5526e-10, 1.4676e-09, 3.5309e-07, 3.9927e-10, 5.4365e-10,\n",
      "        1.9926e-09, 2.6894e-08, 7.9606e-09, 2.7308e-08, 9.0481e-09, 1.2862e-08,\n",
      "        2.7909e-08, 1.4930e-08, 3.8516e-09, 1.2093e-09, 2.5318e-09, 6.6169e-10,\n",
      "        5.3130e-10, 1.7662e-10, 1.9097e-10, 4.2868e-08, 1.0570e-09, 2.9296e-09,\n",
      "        3.2972e-05, 3.6100e-09, 6.0170e-09, 2.1617e-08, 3.4833e-10, 2.5223e-10,\n",
      "        1.8294e-10, 8.8941e-11, 1.3953e-09, 1.5711e-08, 4.5544e-08, 1.3473e-10,\n",
      "        1.1565e-09, 1.2145e-10, 6.4610e-12, 3.0524e-09, 5.4062e-09, 2.3275e-09,\n",
      "        1.1608e-08, 2.5271e-09, 1.6108e-10, 4.2361e-10, 3.0078e-11, 4.7622e-10,\n",
      "        5.3341e-07, 2.4745e-10, 3.6897e-10, 2.0069e-08, 4.2901e-09, 2.7539e-09,\n",
      "        3.3251e-09, 1.2143e-08, 1.5683e-10, 4.0136e-08, 4.0235e-10, 2.9570e-11,\n",
      "        2.5250e-09, 1.0188e-09, 1.7241e-07, 7.5895e-10, 2.3725e-09, 3.4037e-10,\n",
      "        7.2720e-09, 4.8409e-10, 2.5003e-08, 2.3442e-08, 1.6624e-08, 3.0040e-09,\n",
      "        3.2925e-11, 1.5019e-08, 4.9331e-08, 1.0175e-08, 1.5616e-07, 5.9035e-09,\n",
      "        1.6773e-10, 1.0831e-09, 1.7994e-09, 3.4435e-10, 1.3957e-08, 5.6932e-08,\n",
      "        2.2045e-07, 1.6029e-09, 9.3130e-09, 5.4158e-08, 1.2321e-09, 3.2180e-12,\n",
      "        9.6130e-09, 2.9524e-10, 7.1519e-11, 2.5349e-10, 3.1237e-09, 2.2677e-09,\n",
      "        7.4961e-10, 1.0145e-09, 5.4384e-11, 1.2203e-09, 1.2651e-10, 2.2586e-08,\n",
      "        7.4899e-10, 6.3954e-11, 3.0620e-11, 3.3394e-11, 4.9829e-10, 4.6617e-08,\n",
      "        6.1989e-09, 3.7537e-09, 1.3086e-08, 3.5881e-10, 9.2969e-10, 1.2653e-10,\n",
      "        1.4810e-10, 8.9969e-09, 1.5336e-09, 4.8011e-10, 4.9059e-09, 9.0518e-10,\n",
      "        7.7321e-09, 6.8303e-09, 1.9134e-09, 1.0448e-08, 2.8038e-10, 2.1111e-08,\n",
      "        1.2811e-10, 2.6185e-09, 1.7146e-10, 1.0523e-07, 5.1967e-08, 7.9083e-10,\n",
      "        6.6974e-09, 2.7197e-09, 3.9213e-10, 1.2158e-10, 1.8725e-10, 2.7359e-10,\n",
      "        3.5190e-09, 4.0687e-09, 4.2392e-08, 2.5127e-09, 1.2367e-07, 4.5250e-09,\n",
      "        4.4349e-09, 3.4469e-09, 1.9156e-08, 1.3012e-06, 1.0981e-08, 1.7215e-07,\n",
      "        2.6738e-09, 1.7450e-08, 1.1594e-09, 2.0933e-11, 3.1516e-09, 4.3036e-11,\n",
      "        2.8817e-09, 2.5570e-09, 2.4025e-09, 2.0186e-08, 5.4460e-09, 2.6420e-08,\n",
      "        3.6372e-07, 5.3256e-08, 1.6076e-10, 1.9116e-10, 3.0533e-10, 5.0795e-09,\n",
      "        5.3496e-09, 4.1627e-11, 1.8891e-09, 2.5861e-08])\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10472  100 10472    0     0  36839      0 --:--:-- --:--:-- --:--:-- 36873\n"
     ]
    }
   ],
   "source": [
    "# Download ImageNet labels\n",
    "!curl -O https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.9735875129699707\n",
      "Pomeranian 0.015272324904799461\n",
      "Eskimo dog 0.002251048805192113\n",
      "white wolf 0.0018997897859662771\n",
      "Great Pyrenees 0.0016386007191613317\n"
     ]
    }
   ],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
